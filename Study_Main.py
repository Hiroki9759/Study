# -*- coding: utf-8 -*-
"""Untitled

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zL1tvO_AKuqThFtl1KN7QsC5Zz6c6gj6
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 1.x magic
#!pip install music21
#!pip install keras-gcn
#!pip install hyperas==0.4.1
from __future__ import print_function,division, absolute_import
import os
import glob
import csv
import math
import time
import h5py
import numpy as np
import tensorflow as tf
import pretty_midi
from tensorflow.keras.optimizers import Adam
from music21 import converter, instrument, note, chord, stream
import keras
from keras import Sequential , layers, activations, initializers, constraints, regularizers
from keras.engine import Layer
from keras.layers.core import Reshape, Dense, Dropout,Activation,Flatten
from keras.layers import Input,Dropout,RepeatVector, Dense, TimeDistributed,Embedding,LSTM,UpSampling2D, CuDNNLSTM,Flatten,concatenate,Lambda,Conv2D
from keras.optimizers import Adam,RMSprop
from keras.layers.advanced_activations import LeakyReLU
from keras.layers.normalization import *
from keras.activations import *
from keras.optimizers import *
from keras.models import Model, load_model
from keras.regularizers import l2
import keras.backend as K
import scipy.sparse as sp
from scipy.sparse.linalg.eigen.arpack import eigsh, ArpackNoConvergence
from keras_gcn import GraphConv
import random
import hyperas
import torch as th
import datetime
import torch.nn as nn
import torch.nn.functional as F
from keras.callbacks import TensorBoard

# from tensorflow.nn import sigmoid_cross_entropy_with_logits
from hyperopt import Trials, STATUS_OK, tpe, rand
from hyperas import optim
from hyperas.distributions import choice, uniform
# from PIL import Image
import matplotlib.pyplot as plt
import ssl
import smtplib
from email.mime.text import MIMEText
from email.utils import formatdate
midi_dir = ''
out_dir = 'output'
pitch = ["C","C#","D","D#","E","F","F#","G","G#","A","A#","B","C"]
notesize = 64
pitchsize = 48
FROM_ADDRESS = 'hiroki338@gmail.com'
MY_PASSWORD = 'Hiroki9759'
TO_ADDRESS = '107hiroki@gmail.com'
np.set_printoptions(threshold=np.inf)



def pitch_to_note(pitchname):
    for i in range(128):
        if(pitchname == pitch[i%12] + str(int(i/12)-1)):
            return i
        elif(pitchname == pitch[i%12+1] + str(-1*(int(i/12)-1))):
            return i
def note_to_pitch(notee, k):
    notesize = 64
    pitchsize = 48
    notee = np.array(notee)
    # print(len(notee))
    # k = random.randint(0,len(notee)-1)
    
    pm = pretty_midi.PrettyMIDI(resolution=220,initial_tempo=120.0)
    instrument = pretty_midi.Instrument(0)
    for j in range(pitchsize):
        for i in range(notesize):
            element = notee[k,j,i]
            if(element > 0.8):
                note = pretty_midi.Note(velocity=100,pitch=j+60,start=i*0.125,end=(i+1)*0.125)
                instrument.notes.append(note)
                pm.instruments.append(instrument)
    count = 0
    for note in instrument.notes:
        count += 1
    print(count)
    if count > 100 or count < 5:
        am = pretty_midi.PrettyMIDI(resolution=220,initial_tempo=120.0)
        instrument = pretty_midi.Instrument(0)
        return None
    else:
        
        print(pm)
        return pm
def note_to_pitchi(notee):
    notesize = 64
    pitchsize = 48
    notee = np.array(notee)
    # print(len(notee))
    k = random.randint(0,len(notee)-1)
    pm = pretty_midi.PrettyMIDI(resolution=220,initial_tempo=120.0)
    instrument = pretty_midi.Instrument(0)
    for j in range(pitchsize):
        for i in range(notesize):
            element = notee[k,j,i]
            if(element > 0.8):
                note = pretty_midi.Note(velocity=100,pitch=j+60,start=i*0.125,end=(i+1)*0.125)
                instrument.notes.append(note)
    pm.instruments.append(instrument)
    count = 0
    for note in instrument.notes:
        count += 1
    return count, k
"""
def genX_to_song(gen_X):
    notesize = 64
    pitchsize = 128

    pm = pretty_midi.PrettyMIDI(resolution=220,initial_tempo=120.0)
    instrument = pretty_midi.Instrument(0)
    for j in range(pitchsize):
        for i in range(notesize):
            element = gen_X[j,i]
            if(element>0.4):
                note = pretty_midi.Note(velocity=100,pitch = j , start = i*0.125,end = (i+1)*0.125)
                instrument.notes.append(note)
    pm.instruments.append(instrument)
    # pm.write('Gen_X\gen_X_'+str(k)+'.mid')
    return pm
"""

def note_to_pitch_01(notee, k):
    notesize = 64
    pitchsize = 48
    notee = np.array(notee)
    # print(len(notee))
    # k = random.randint(0,len(notee)-1)
    
    pm = pretty_midi.PrettyMIDI(resolution=220,initial_tempo=120.0)
    instrument = pretty_midi.Instrument(0)
    for j in range(pitchsize):
        for i in range(notesize):
            element = notee[k,j,i]
            if(element > 0.1):
                note = pretty_midi.Note(velocity=100,pitch=j+60,start=i*0.125,end=(i+1)*0.125)
                instrument.notes.append(note)
                pm.instruments.append(instrument)
    count = 0
    for note in instrument.notes:
        count += 1
    print(count)
    if count > 100 or count < 5:
        am = pretty_midi.PrettyMIDI(resolution=220,initial_tempo=120.0)
        instrument = pretty_midi.Instrument(0)
        return None
    else:
        
        print(pm)
        return pm
def note_to_pitchi_01(notee):
    notesize = 64
    pitchsize = 48
    notee = np.array(notee)
    # print(len(notee))
    k = random.randint(0,len(notee)-1)
    pm = pretty_midi.PrettyMIDI(resolution=220,initial_tempo=120.0)
    instrument = pretty_midi.Instrument(0)
    for j in range(pitchsize):
        for i in range(notesize):
            element = notee[k,j,i]
            if(element > 0.1):
                note = pretty_midi.Note(velocity=100,pitch=j+60,start=i*0.125,end=(i+1)*0.125)
                instrument.notes.append(note)
                pm.instruments.append(instrument)
    count = 0
    for note in instrument.notes:
        count += 1
    return count, k
def note_to_pitch_02(notee, k):
    notesize = 64
    pitchsize = 48
    notee = np.array(notee)
    # print(len(notee))
    # k = random.randint(0,len(notee)-1)
    
    pm = pretty_midi.PrettyMIDI(resolution=220,initial_tempo=120.0)
    instrument = pretty_midi.Instrument(0)
    for j in range(pitchsize):
        for i in range(notesize):
            element = notee[k,j,i]
            if(element > 0.999):
                note = pretty_midi.Note(velocity=100,pitch=j+60,start=i*0.125,end=(i+1)*0.125)
                instrument.notes.append(note)
                pm.instruments.append(instrument)
    count = 0
    for note in instrument.notes:
        count += 1
    print(count)
    if count > 100 or count < 5:
        am = pretty_midi.PrettyMIDI(resolution=220,initial_tempo=120.0)
        instrument = pretty_midi.Instrument(0)
        return None
    else:
        
        print(pm)
        return pm
def note_to_pitchi_02(notee):
    notesize = 64
    pitchsize = 48
    notee = np.array(notee)
    # print(len(notee))
    k = random.randint(0,len(notee)-1)
    pm = pretty_midi.PrettyMIDI(resolution=220,initial_tempo=120.0)
    instrument = pretty_midi.Instrument(0)
    for j in range(pitchsize):
        for i in range(notesize):
            element = notee[k,j,i]
            if(element > 0.999):
                note = pretty_midi.Note(velocity=100,pitch=j+60,start=i*0.125,end=(i+1)*0.125)
                instrument.notes.append(note)
                pm.instruments.append(instrument)
    count = 0
    for note in instrument.notes:
        count += 1
    return count, k

X_train=np.load('output\_tuned_Chinese_small48_X_train.npy')
A_train=np.load('output\_tuned_Chinese_small48_A_train.npy')
print(len(X_train))
print(len(A_train))
SYM_NORM = True 
class GAN():
    
    def __init__(self):
        notesize = 64
        pitchsize = 48
        self.graph = []
        #データ用の入力データサイズ
        self.X_rows = pitchsize
        self.X_cols = notesize
        self.X_channels = 1
        self.X_shape = (self.X_rows, self.X_cols)
        
        self.A_rows = pitchsize 
        self.A_cols = pitchsize
        self.A_channels = 1
        self.A_shape = (self.A_rows, self.A_cols)
        # 潜在変数の次元数 
        self.z_dim = 32
        
        optimizer = Adam(0.0002, 0.5)
        # self.G = [Input(shape=(pitchsize,notesize),batch_shape=None,sparse=False)]
        # discriminatorモデル
        
        self.discriminator = self.create_discriminator()
        self.discriminator.compile(loss='binary_crossentropy', 
            optimizer=optimizer,
            metrics=['accuracy'])

        # Generatorモデル
        self.Xgenerator = self.create_Xgenerator()
        self.Agenerator = self.create_Agenerator()
        # generatorは単体で学習しないのでコンパイルは必要ない
        # self.Xgenerator.compile(loss='binary_crossentropy', optimizer=optimizer)
        # self.Agenerator.compile(loss = 'binary_crossentropy', optimizer = optimizer)
        
        self.combined = self.build_combined2()
        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)
    def create_Xgenerator(self):
        Z_in = Input(shape=(self.z_dim,))
        H = Dense(128)(Z_in)
        H = LeakyReLU(0.24699647319285056)(H)
        H = BatchNormalization(momentum=0.6912889708363212)(H)
        # H = Dense(128)(H)
        # H = LeakyReLU(0.4963711765213895)(H)
        # H = Dropout(0.5)(H)
        # H = BatchNormalization(momentum=0.8516669020645388)(H)
        # H = Dense(512)(H)
        # H = LeakyReLU(0.9810552442495526)(H)
        # H = Dropout(0.5)(H)
        # H = BatchNormalization(momentum=0.7554019665100291)(H)
        # H = Dense(2048)(H)
        # H = LeakyReLU(0.06569535214198996)(H)
        H = Dense(np.prod(self.X_shape), activation='tanh')(H)
        H = Reshape(self.X_shape)(H)
        Xgenerator = Model(Z_in,H,name='Xgenerator')
        Xgenerator.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.25634389232531474,beta_1=0.7366398259976741,beta_2=0.7871478922143195,decay=0.21887493324099216))
        Xgenerator.summary()
        return Xgenerator
    # def create_Xgenerator(self):
    #     Z_in = Input(shape=(self.z_dim,))
    #     H = Dense(6*8*128)(Z_in)
    #     H = LeakyReLU()(H)
    #     H = Reshape((6,8,128))(H)
    #     H = BatchNormalization(momentum=0.8)(H)
    #     H = UpSampling2D()(H)
    #     H = Conv2D(128,kernel_size=1,padding="same")(H)
    #     H = LeakyReLU()(H)
    #     H = BatchNormalization()(H)
    #     H = UpSampling2D()(H)
    #     H = Conv2D(32,kernel_size=1,padding="same")(H)
    #     H = LeakyReLU()(H)
    #     H = BatchNormalization()(H)
    #     H = UpSampling2D()(H)
    #     H = Conv2D(1,kernel_size=1,padding="same")(H)
    #     H = LeakyReLU()(H)
    #     H = Reshape((48,64))(H)
    #     Xgenerator = Model(Z_in,H,name='Xgenerator')
    #     Xgenerator.compile(loss='binary_crossentropy', optimizer=Adam(lr = 1e-4))#lr=0.25634389232531474,beta_1=0.7366398259976741,beta_2=0.7871478922143195,decay=0.21887493324099216
    #     Xgenerator.summary()
    #     return Xgenerator
        
    # def create_Agenerator(self):
    #     Z_in = Input(shape=(self.z_dim,))
    #     H = Dense(6*6*128)(Z_in)
    #     H = LeakyReLU()(H)
    #     H = Reshape((6,6,128))(H)
    #     H = BatchNormalization(momentum=0.8)(H)
    #     H = UpSampling2D()(H)
    #     H = Conv2D(128,kernel_size=1,padding="same")(H)
    #     H = LeakyReLU()(H)
    #     H = BatchNormalization()(H)
    #     H = UpSampling2D()(H)
    #     H = Conv2D(32,kernel_size=1,padding="same")(H)
    #     H = LeakyReLU()(H)
    #     H = BatchNormalization()(H)
    #     H = UpSampling2D()(H)
    #     H = Conv2D(1,kernel_size=1,padding="same")(H)
    #     H = LeakyReLU()(H)
    #     H = Reshape((48,48))(H)
    #     Agenerator = Model(Z_in,H,name='Agenerator')
    #     Agenerator.compile(loss='binary_crossentropy', optimizer=Adam(lr=1e-4)) #beta_1=0.7366398259976741,beta_2=0.7871478922143195,decay=0.21887493324099216
    #     Agenerator.summary()
    #     return Agenerator






    def create_Agenerator(self):
        Z_in = Input(shape=(self.z_dim,))
        H = Dense(128)(Z_in)
        H = LeakyReLU(0.12064860770171626)(H)
        H = BatchNormalization(momentum=0.1602501347478713)(H)
        # H = Dense(128)(H)
        # H = LeakyReLU(0.06613267728888905)(H)
        # H = Dropout(0.5)(H)
        # H = BatchNormalization(momentum=0.19549908453898146)(H)
        # H = Dense(512)(H)
        # H = LeakyReLU(0.6060162101952701)(H)
        # H = Dropout(0.5)(H)
        # H = BatchNormalization(momentum=0.7184027740571731)(H)
        # H = Dense(2048)(H)
        # H = LeakyReLU(0.11729755246044238)(H)
        H = Dense(np.prod(self.A_shape), activation='tanh')(H)
        H = Reshape(self.A_shape)(H)
        Agenerator = Model(Z_in,H,name='Agenerator')
        Agenerator.compile(loss='binary_crossentropy', optimizer=Adam(lr= 0.8444244099007299,beta_1=0.8368172765965655,beta_2=0.8005863373561044,decay=0.9054419122145128))
        Agenerator.summary()
        return Agenerator
    
    def create_discriminator(self):
        # モデルの構築
        X_in = Input(shape=(pitchsize,notesize))
        A = Input(shape=(pitchsize,pitchsize))
        H = GraphConv(notesize)([X_in,A])
        # H = GraphConv(notesize)([H,A])
        # H = GraphConv(notesize)([H,A])
        H = Flatten()(H)
        H = Dropout(0.5350807190884803)(H)
        Y = Dense(2048)(H)
        # Y = LeakyReLU( 0.7014222854136862)(Y)       
        # Y = Dropout(0.5350807190884803)(Y)
        # Y = Dense(1024)(Y)
        # Y = LeakyReLU( 0.7014222854136862)(Y)       
        # Y = Dropout(0.5350807190884803)(Y)
        # Y = Dense(256)(Y)
        # Y = LeakyReLU( 0.7014222854136862)(Y)       
        # Y = Dropout(0.5350807190884803)(Y)
        # Y = Dense(128)(Y)
        Y = LeakyReLU( 0.7014222854136862)(Y)       
        # Y = Dropout(0.5350807190884803)(Y)
        # Y = Dense(8)(Y)
        # Y = LeakyReLU( 0.7014222854136862)(Y)
        Y = Dense(1,activation='sigmoid')(Y)
        # コンパイル
        discriminator = Model(inputs=[X_in,A], outputs=Y, name='Discriminator')
        discriminator.compile(loss='binary_crossentropy', optimizer=SGD(lr=0.5445786237304729,momentum=0.14782757761941956,decay=0.5474680409662654,nesterov=False))
        discriminator.summary()
        return discriminator
    
    def build_combined2(self):
        z = Input(shape=(self.z_dim,))
        X = self.Xgenerator(z)
        A = self.Agenerator(z)
        support = 1
        self.discriminator.trainable=False
        gan_V = self.discriminator([X,A])
        self.discriminator.trainable=False
        model = Model(inputs=z,outputs=gan_V,name='Model')
        model.compile(loss='binary_crossentropy',optimizer=Adam(lr= 0.9203644803497606,beta_1=0.952182609478963,beta_2=0.4491682347001641,decay= 0.044317063543799606))
        model.summary()
        return model

    def train(self, steps, batch_size=64, save_interval=50):
        date = datetime.datetime.now()
        NOW = str(date.year)+"-"+str(date.month)+"-"+str(date.day)+"-"+str(date.hour)+"-"+str(date.minute)+"-"+str(date.second)+"-"
        half_batch = int(batch_size/2)
        f = open(os.path.join(out_dir, 'gan_log'+NOW+'.csv'),'a')
        writer = csv.writer(f)

        def write_log(callback, names, logs, batch_no):
            for name, value in zip(names, logs):
                summary = tf.Summary()
                summary_value = summary.value.add()
                summary_value.simple_value = value
                summary_value.tag = name
                callback.writer.add_summary(summary, batch_no)
                callback.writer.flush()
        noise = np.random.normal(0, 1, (batch_size, self.z_dim))
        
        log_path = './logs/log'+NOW
        callback = TensorBoard(log_path)
        callback.set_model(self.combined)
        train_names = ['d_loss', 'accuracy','g_loss']
        startstep = time.time()
        for step in range(steps):
            train_time = time.time() - startstep
            graphs = []
            
            # ---------------------
            #  Discriminatorの学習
            # ---------------------
            noise = np.random.rand(batch_size,self.z_dim)
            # バッチサイズの半数をGeneratorから生成
            noise_half = np.random.normal(-1, 1, (half_batch, self.z_dim))
            # noise = np.random.uniform(-1,1,(half_batch,self.z_dim))
           
            
            for t in range(0,len(X_train)//batch_size):  
                trans_X =[]
                # バッチサイズの半数を教師データからピックアップ
                idx = np.random.randint(0,len(X_train), half_batch)
                #print(idx)
                gen_A = self.Agenerator.predict(noise_half)
                gen_X = self.Xgenerator.predict(noise_half)
                #
                # gen_X = self.Xgenerator.predict(noise_half)
                # for i in range(len(gen_X)):
                #     X,A =gen_X_transform(genX_to_song(gen_X[i]))
                #     trans_X.append(X)
                graphsX = []
                graphsA = []
                for i in idx:
                    graphsX.append(X_train[i])
                    graphsA.append(A_train[i])
                graphs = [graphsX,graphsA]
             
                
                
                
                
                valid_y = np.array([1] * batch_size)
                # noise = np.random.rand(batch_size,self.z_dim)
                noise = np.random.normal(-1, 1, (batch_size, self.z_dim))
                # noise = np.random.uniform(0,1,(batch_size,self.z_dim))
                g_loss = self.combined.train_on_batch(noise, valid_y)
                noise = np.random.normal(-1, 1, (batch_size, self.z_dim))
                # # noise = np.random.uniform(0,1,(batch_size,self.z_dim))
                # noise = np.random.rand(batch_size,self.z_dim)
                g_loss = self.combined.train_on_batch(noise, valid_y)
                # discriminatorを学習
                # 本物データと偽物データは別々に学習させる
                d_loss_real = self.discriminator.train_on_batch(graphs, np.ones((half_batch, 1)))
                d_loss_fake = self.discriminator.train_on_batch([gen_X,gen_A], np.zeros((half_batch, 1)))
                # それぞれの損失関数を平均
                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)
                
                # ---------------------
                #  Generatorの学習
                # ---------------------

                noise = np.random.normal(-1, 1, (batch_size, self.z_dim))
                # noise = np.random.rand(batch_size,self.z_dim)
                # Train the generator
                g_loss = self.combined.train_on_batch(noise, valid_y)
                noise = np.random.normal(-1, 1, (batch_size, self.z_dim))
                # noise = np.random.rand(batch_size,self.z_dim)
                # noise = np.random.uniform(0,1,(batch_size,self.z_dim))
                g_loss = self.combined.train_on_batch(noise, valid_y)
                
            
            writer.writerow([step, d_loss, g_loss])
            # 進捗の表示
            date1 = datetime.datetime.now()
            NOW1 = str(date1.year)+"-"+str(date1.month)+"-"+str(date1.day)+"-"+str(date1.hour)+"-"+str(date1.minute)+"-"+str(date1.second)+"-"
            counter_01,k_01 = note_to_pitchi_01(gen_X)
            counter, k =  note_to_pitchi(gen_X)
            counter_02,k_02 = note_to_pitchi_01(gen_X)
            print ("%d [D loss: %f, acc.: %.2f%%] [G loss: %f]|counter: %d" % (step, d_loss[0], 100*d_loss[1], g_loss,counter))
            print(NOW1+"elapsed_time:{0}".format(train_time) + "[sec]")
            
            # if counter < 100 and counter !=0 :
            #     with open("CSVfolder\gen_X_"+NOW1+str(step)+".csv","a") as fl:
            #         fl.write(str(gen_X))
            #     with open("CSVfolder\gen_A_"+NOW1+str(step)+".csv","a") as fm:
            #         fm.write(str(gen_A))
            #     for k in range (0, half_batch-1):
            #         if note_to_pitch(gen_X,k) != None:
            #             note_to_pitch(gen_X,k).write('Generated_Midi_Files\gen_'+NOW1 + str(step)+'_'+str(k)+'_' + '.mid')
            #     print(len(gen_X)) 
            #     np.save("NPY_files\gen_X_"+NOW1+str(step),gen_X)
            #     # self.g_loss_array[step] = g_loss
            #     # self.d_loss_array[step] = d_loss[0]
            #     # self.d_accuracy_array[step] = 100. * d_loss[1]
            #     self.Xgenerator.save_weights('Weightfolder\Xgenerator'+NOW1+str(step)+'.h5')
            #     self.Agenerator.save_weights('Weightfolder\Agenerator'+NOW1+str(step)+'.h5')
            #     self.discriminator.save_weights('Weightfolder\discriminator'+NOW1+str(step)+'.h5')
            #     self.combined.save('Weightfolder\Iwagan_6.h5')
                # subject = "IwaGAN report"
                # body = str(step) + "d_loss:" + str(d_loss[0]) +"g_loss:"+str(g_loss) + "accuracy:"  + str(d_loss[1])+str(counter)
                # msg=MIMEText(body,"html")
                # msg["Subject"] = subject
                # msg["To"] = TO_ADDRESS
                # msg["From"] = FROM_ADDRESS
                # server = smtplib.SMTP_SSL("smtp.gmail.com", 465,context=ssl.create_default_context())
                # server.login(FROM_ADDRESS,MY_PASSWORD)
                # server.send_message(msg)
                # print("mail,sended!")
            # if counter_01 < 100 and counter_01 !=0 :
            #     with open("CSVfolder\gen_X_"+NOW1+str(step)+"_01.csv","a") as fl:
            #         fl.write(str(gen_X))
            #     with open("CSVfolder\gen_A_"+NOW1+str(step)+"_01.csv","a") as fm:
            #         fm.write(str(gen_A))
            #     for k in range (0, half_batch-1):
            #         if note_to_pitch_01(gen_X,k) != None:
            #             note_to_pitch_01(gen_X,k).write('Generated_Midi_Files\gen_'+NOW1 + str(step)+'_'+str(k)+'_01' + '.mid')
            #     print(len(gen_X)) 
            #     np.save("NPY_files\gen_X_01_"+NOW1+str(step),gen_X)
            #     # self.g_loss_array[step] = g_loss
            #     # self.d_loss_array[step] = d_loss[0]
            #     # self.d_accuracy_array[step] = 100. * d_loss[1]
            #     self.Xgenerator.save_weights('Weightfolder\Xgenerator'+NOW1+str(step)+'_01.h5')
            #     self.Agenerator.save_weights('Weightfolder\Agenerator'+NOW1+str(step)+'_01.h5')
            #     self.discriminator.save_weights('Weightfolder\discriminator'+NOW1+str(step)+'_01.h5')
            #     self.combined.save('Weightfolder\Iwagan_6_01.h5')
            #     # subject = "IwaGAN report"
            #     # body = str(step) + "d_loss:" + str(d_loss[0]) +"g_loss:"+str(g_loss) + "accuracy:"  + str(d_loss[1])+str(counter_01)
            #     # msg=MIMEText(body,"html")
            #     # msg["Subject"] = subject
            #     # msg["To"] = TO_ADDRESS
            #     # msg["From"] = FROM_ADDRESS
            #     # server = smtplib.SMTP_SSL("smtp.gmail.com", 465,context=ssl.create_default_context())
            #     # server.login(FROM_ADDRESS,MY_PASSWORD)
            #     # server.send_message(msg)
            #     # print("mail,sended!")
            # if counter_02 < 100 and counter_02 !=0 :
            #     with open("CSVfolder\gen_X_"+NOW1+str(step)+"02.csv","a") as fl:
            #         fl.write(str(gen_X))
            #     with open("CSVfolder\gen_A_"+NOW1+str(step)+"02.csv","a") as fm:
            #         fm.write(str(gen_A))
            #     for k in range (0, half_batch-1):
            #         if note_to_pitch(gen_X,k) != None:
            #             note_to_pitch(gen_X,k).write('Generated_Midi_Files\gen_'+NOW1 + str(step)+'_'+str(k)+'_02' + '.mid')
            #     print(len(gen_X)) 
            #     np.save("NPY_files\gen_X_02"+NOW1+str(step),gen_X)
            #     # self.g_loss_array[step] = g_loss
            #     # self.d_loss_array[step] = d_loss[0]
            #     # self.d_accuracy_array[step] = 100. * d_loss[1]
            #     self.Xgenerator.save_weights('Weightfolder\Xgenerator'+NOW1+str(step)+'02.h5')
            #     self.Agenerator.save_weights('Weightfolder\Agenerator'+NOW1+str(step)+'02.h5')
            #     self.discriminator.save_weights('Weightfolder\discriminator'+NOW1+str(step)+'02.h5')
            #     self.combined.save('Weightfolder\Iwagan_6_02.h5')
            if step % save_interval == 0:
                with open("CSVfolder\gen_X_"+NOW1+str(step)+".csv","a") as fl:
                    fl.write(str(gen_X))
                with open("CSVfolder\gen_A_"+NOW1+str(step)+".csv","a") as fm:
                    fm.write(str(gen_A))
                for k in range(0,half_batch):
                    if note_to_pitch(gen_X,k) != None:
                        note_to_pitch(gen_X,k).write('Generated_Midi_Files\gen_'+NOW1 + str(step)+'_'+str(k)+'_' + '.mid')
                    # note_to_pitch(gen_X,k).write('gen_'+NOW + str(step)+ '_'+str(k) +'_' + '.mid')
                # print(len(gen_X))
                # print(gen_X)            
                # self.g_loss_array[step] = g_loss
                # self.d_loss_array[step] = d_loss[0]
                # self.d_accuracy_array[step] = 100. * d_loss[1]
                self.Xgenerator.save_weights('Weightfolder\Xgenerator'+NOW1+str(step)+'.h5')
                self.Agenerator.save_weights('Weightfolder\Agenerator'+NOW1+str(step)+'.h5')
                self.discriminator.save_weights('Weightfolder\discriminator'+NOW1+str(step)+'.h5')
                self.combined.save('Weightfolder\Iwagan_6.h5')
                np.save("NPY_files\gen_X_02"+NOW1+str(step),gen_X)
               

            write_log(callback,train_names,[d_loss[0],d_loss[1],g_loss],step)
        f.close()
if __name__ == '__main__':
    gan = GAN()
    gan.train(steps=10001, batch_size=128, save_interval=250)
    
    # print("mail,sended!")
    # X_train=np.load('output\_tuned_Chinese_small48_X_train.npy')
    # A_train=np.load('output\_tuned_Chinese_small48_A_train.npy')
    # gan = GAN()
    # gan.train(steps=2000, batch_size=64, save_interval=250)
    
    # X_train=np.load('output\_tuned_Fork_small48_X_train.npy')
    # A_train=np.load('output\_tuned_Fork_small48_A_train.npy')
    # gan = GAN()
    # gan.train(steps=2000, batch_size=64, save_interval=250)
   
   
    # X_train=np.load('output\_tuned_Hindu_small48_X_train.npy')
    # A_train=np.load('output\_tuned_Hindu_small48_A_train.npy')
    # gan = GAN()
    # gan.train(steps=1200, batch_size=64, save_interval=250)
  
